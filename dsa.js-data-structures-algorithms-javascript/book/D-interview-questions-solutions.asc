<<<
[appendix]
[[d-interview-questions-solutions]]
== Interview Questions Solutions
(((Interview Questions Solutions)))

=== Solutions for Array Questions
(((Interview Questions Solutions, Arrays)))

:leveloffset: -1

[#array-q-max-subarray]
include::content/part02/array.asc[tag=array-q-max-subarray]

The first step is making sure we understand the problem well. Let's do basic examples:

----
A = [-5, 6, 9, -8]
B = [-1, 6, -3, 8]
----

What's the subarray with the maximum sum? For A, it will be `[6, 9]` and for B, it will be `[6, -3, 8]`.

We could generate all possible subarrays, add them up, and then pick the max number.

[source, javascript]
----
include::interview-questions/max-subarray.js[tag=maxSubArrayBrute1]
----

This code is simple to understand; however, not very efficient. The runtime is `O(n^3)`.

Notice we're adding up the numbers from `i` to `j` on each cycle. But, we can optimize this. We can keep a local variable and add the new number to it. That way, we don't have to revisit previous numbers.

[source, javascript]
----
include::interview-questions/max-subarray.js[tag=maxSubArrayBrute2]
----

The runtime is much better: `O(n)`. Can we still do better?

We can use a greedy approach, where do one pass through the array. We only add the numbers if their sum is larger than just taking the current element.

[source, javascript]
----
include::interview-questions/max-subarray.js[tag=description]
include::interview-questions/max-subarray.js[tag=solution]
----

The runtime is `O(n)` and the space complexity of `O(1)`.




[#array-q-buy-sell-stock]
include::content/part02/array.asc[tag=array-q-buy-sell-stock]

There are multiple examples that we can simulate: bear markets (when prices are going down), bullish markets (when prices are going up), and zig-zag markets (when prices are going up and down).

[source, javascript]
----
// zig-zag market
maxProfit([5, 10, 5, 10]); // => 5
// bullish market
maxProfit([1, 2, 3]); // => 2
// bearish market
maxProfit([3, 2, 1]); // => 0
----

During the bearish markets, the profit will always be 0. Since if you buy, we are only going to lose.

We can do a brute force solution doing all combinations:

[source, javascript]
----
include::interview-questions/buy-sell-stock.js[tag=maxProfitBrute1]
----

The runtime for this solution is `O(n^2)`.

A better solution is to eliminate the 2nd for loop and only do one pass.

Algorithm:

- Do one pass through all the prices
    ** Keep track of the minimum price seen so far.
    ** calculate `profit = currentPrice - minPriceSoFar`
    ** Keep track of the maximun profit seen so far.
- Return maxProfit.

[source, javascript]
----
include::interview-questions/buy-sell-stock.js[tags=description;solution]
----

The runtime is `O(n)` and the space complexity of `O(1)`.



:leveloffset: +1

=== Solutions for Linked List Questions
(((Interview Questions Solutions, Linked Lists)))

:leveloffset: -1




[#linkedlist-q-merge-lists]
include::content/part02/linked-list.asc[tag=linkedlist-q-merge-lists]

We need to visit each node in both lists and merge them in ascending order. Note: We don't need to copy the values nor create new nodes.

Another case to take into consideration is that lists might have different lengths. So, if one list runs out, we have to keep taking elements from the remaining list.

*Algorithm*:

- Have a pointer for each list
- While there's a pointer that is not null, visite them
    ** Compare each list node's value and take the smaller one.
    ** Advance the pointer of the taken node to the next one.

*Implementation*:

[source, javascript]
----
include::interview-questions/merge-lists.js[tags=description;solution]
----

Notice that we used a "dummy" node or "sentinel node" to have some starting point for the final list.

*Complexity Analysis*:

- Time: `O(m+n)`. Visiting each node from the list 1 and list 2 has a time complexity `O(m + n)`. `m` and `n` represent each list's length.
- Space: `O(1)`. We reuse the same nodes and only change their `next` pointers. We only create one additional node, "the sentinel node."


[#linkedlist-q-linkedlist-same-data]
include::content/part02/linked-list.asc[tag=linkedlist-q-linkedlist-same-data]

We are given two linked lists that contain string data. We want to know if the concatenated strings from each list are the same.

The tricky part is that the same data can be distributed differently on the linked lists:

----
L1: he -> ll -> o
L2: h -> e -> llo
----

One naive approach could be to go through each list's node and concatenate the strings. Then, we can check if they are equal.

[source, javascript]
----
include::interview-questions/linkedlist-same-data.js[tag=hasSameDataBrute1]
----

Notice that the problem mentions that lists could be huge (millions of nodes). If the first character on each list is different, we are unnecessarily computing millions of nodes, when a straightforward check will do the job.

A better way to solve this problem is iterating over each character on both lists, and when we found a mismatch, we return `false` immediately. If they are the same, we still have to visit all of them.

*Algorithm*:

- Set a pointer to iterate over each node in the lists.
- For each node, have an index (starting at zero) and compare if both lists have the same data.
    ** When the index reaches the last character on the current node, we move to the next node.
    ** If we found that a character from one list doesn't match the other, we return `false`.

*Implementation*:

[source, javascript]
----
include::interview-questions/linkedlist-same-data.js[tags=description;solution]
----

The function `findNextPointerIndex` is a helper to navigate each character on a linked list.
Notice that we increase the index (`i + 1`) on each iteration.
If the index overflows, it moves to the next node and reset the index to zero.



*Complexity Analysis*:

- Time: `O(n)`. We go over all the characters on each list
- Space: `O(1)`. Only using pointers and no auxiliary data structures.



:leveloffset: +1

=== Solutions for Stack Questions
(((Interview Questions Solutions, Stack)))

:leveloffset: -1

[#stack-q-valid-parentheses]
include::content/part02/stack.asc[tag=stack-q-valid-parentheses]

.We need to validate that brackets are correctly opened and closed, following these rules:
- An opened bracket must be close by the same type.
- Open brackets mush be closed in the correct order.

We are facing a parsing problem, and usually, stacks are good candidates for them.

*Algorithm*:

- Create a mapping for each opening bracket to its closing counterpart.
- Iterate through the string
    ** When we found an opening bracket, insert the corresponding closing bracket into the stack.
    ** When we found a closing bracket, pop from the stack and make sure it corresponds to the current character.
- Check the stack is empty. If there's a leftover, it means that something didn't close properly.

*Implementation*:

[source, javascript]
----
include::interview-questions/valid-parentheses.js[tag=description]
include::interview-questions/valid-parentheses.js[tag=solution]
----

*Complexity Analysis*:

- Time: `O(n)`. We iterate over each character of the string.
- Space: `O(n)`. We use an auxiliary stack.



[#stack-q-daily-temperatures]
include::content/part02/stack.asc[tag=stack-q-daily-temperatures]

The first solution that might come to mind it's using two for loops. For each element, we have visit each temperature ahead to find a bigger one.

[source, javascript]
----
include::interview-questions/daily-temperatures.js[tag=dailyTemperaturesBrute1]
----

This solution is an `O(n^2)`. Can we do better? We can!

Here's an idea: start backward, so we know when there's a warmer temperature beforehand. The last element is always 0 (because there are no more temperatures ahead of it). We can place each element's index that we visit on a stack. If the current weather is bigger than the stack top, we remove it until a bigger one remains or the stack is empty. If the stack has a value, we calculate the number of days ahead. Otherwise, it is 0.

*Algorithm*:

- Traverse the daily temperatures backward
  ** Push each temperature to a stack.
  ** While the current temperature is larger than the one at the top of the stack, pop it.
  ** If the stack is empty, then there's no warmer weather ahead, so it's 0.
  ** If the stack has an element, calculate the index delta.

*Implementation*:

[source, javascript]
----
include::interview-questions/daily-temperatures.js[tag=description]
include::interview-questions/daily-temperatures.js[tag=solution]
----

The stack contains the indexes rather than the temperatures themselves.

*Complexity Analysis*:

- Time: `O(n)`. We visit each element on the array once.
- Space: `O(1)`. The worst-case scenario is ascending order without duplicates. The stack will hold at most 70 items (100 - 30). If we didn't have the range restriction, then space complexity would be `O(n)`.



:leveloffset: +1

=== Solutions for Queue Questions
(((Interview Questions Solutions, Queue)))

:leveloffset: -1


[#queue-q-recent-counter]
include::content/part02/queue.asc[tag=queue-q-recent-counter]

We are asked to keep track of the request's count only within a given time window. A queue is a perfect application for this. We can add any new request to the  Queue. Also, we need to check if the oldest element is outside the time window. If so, we remove it from the queue.

*Algorithm*:

- Enqueue new requests.
- Take a `peek` at the oldest request in the queue.
- While `current timestamp - oldest timestamp`, dequeue the oldest.
- Return the length of the queue.

*Implementation*:

[source, javascript]
----
include::interview-questions/recent-counter.js[tags=description;solution]
----

Notice that we enqueue every request, and then we check all the ones that have "expire" and remove them from the queue.

*Complexity Analysis*:

- Time: `O(n)`, where `n` is the number of requests. One Enqueue/Dequeue operation is O(1). However, we might run into a worst-case where all requests have to be dequeued.
- Space: `O(W)`, where `W` is the time window. We can have at most W requests in the queue since they are in increasing order without duplicates.


[#queue-q-design-snake-game]
include::content/part02/queue.asc[tag=queue-q-design-snake-game]

This game is perfect to practice working with Queues. There are at least two opportunities to use a Queue. You can enqueue the food location, and also you can keep the snake's body parts on a Queue. We insert a new position into the snake's queue on every move and dequeue the last location to indicate the snake moved. Every time the snake eats food, it grows one more unit. The food gets dequeue, and we place the next food location (if any).

*Algorithm*:

- Based on the snake's head current position, calculate the next location based on the given move `direction`.
- If the new position is outside the boundaries, it's game over (return -1).
- If the new location has food, remove that eaten food from its queue and place the next food on the map (if any).
- If the new position doesn't have food, remove the tail of the snake since it moved.
- If the snake new position hits itself, game over (return -1). To make this check, we have 2 options:
    ** Queue: we can visit all the elements on the snake's queue (body) and check if a new position collides. That's `O(n)`
    ** Set: we can maintain a `set` with all the snake locations, so the check is `O(1)`.
- Move the snake's head to a new location (enqueue)
- Return the score (snake's length - 1);

*Implementation*:

[source, javascript]
----
include::interview-questions/design-snake-game.js[tags=description;solution]
----

As you can see, we opted for using a set to trade speed for memory.

*Complexity Analysis*:

- Time: `O(1)`. Insert/Remove from Queue is constant time. Check for body collisions is `O(1)` when using a set. If instead of a set, you traversed the snake's queue to find a collision, it would be `O(n)`.  Here`n` is the snake's max length, which is the screen size (height x width).
- Space: `O(n + m)`. `m` is the number of food items, and `n` is the snake's maximum size (height x width).



:leveloffset: +1

=== Solutions for Binary Tree Questions
(((Interview Questions Solutions, Binary Tree)))

:leveloffset: -1

[#binary-tree-q-diameter-of-binary-tree]
include::content/part03/binary-search-tree-traversal.asc[tag=binary-tree-q-diameter-of-binary-tree]

We are asked to find the longest path on a binary tree that might or might not pass through the root node.

We can calculate the height (distance from root to farthest leaf) of a binary tree using this recursive function:

[source, javascript]
----
function getHeight(node) {
  if (!node) return 0;
  const leftHeight = getHeight(node.left);
  const rightHeight = getHeight(node.right);
  return 1 + Math.max(leftHeight, rightHeight);
}
----

That function will give us the height from the furthest leaf to the root. However, the problem says that it might or might not go through the root.
In that case, we can keep track of the maximum distance (`leftHeight + rightHeight`) seen so far.

*Algorithm*:

- Initialize diameter to `0`
- Recursively find the height of the tree from the root.
- Keep track of the maximum diameter length seen so far (left + right).
- Return the diameter.

*Implementation*:

[source, javascript]
----
include::interview-questions/diameter-of-binary-tree.js[tags=description;solution]
----

We are using `Math.max` to keep track of the longest diameter seen.

*Complexity Analysis*:

- Time: `O(n)`, where `n` is each of the tree nodes. We visite each one once.
- Space: `O(n)`. We use `O(1)` variables, but because we are using the `height` recursive function, we use the implicit call stack, thus `O(n)`.




[#binary-tree-q-binary-tree-right-side-view]
include::content/part03/binary-search-tree-traversal.asc[tag=binary-tree-q-binary-tree-right-side-view]

The first thing that might come to mind when you have to visit a tree, level by level, is BFS.
We can visit the tree using a Queue and keep track when a level ends, and the new one starts.

Since during BFS, we dequeue one node and enqueue their two children (left and right), we might have two levels (current and next one). For this problem, we need to know what the last node on the current level is.

.There are several ways to solve this problem by using BFS. Here are some ideas:
- *1 Queue + Sentinel node*: we can use a special character in the `Queue` like `'*'` or `null` to indicate a level change. So, we would start something like this `const queue = new Queue([root, '*']);`.
- *2 Queues*: using a "special" character might be seen as hacky, so you can also opt to keep two queues: one for the current level and another for the next level.
- *1 Queue + size tracking*: we track the Queue's `size` before the children are enqueued. That way, we know where the current level ends.

We are going to implement BFS with "1 Queue + size tracking", since it's arguably the most elegant.

*Algorithm*:

- Enqueue root
- While the queue has an element
    ** Check the current size of the queue
    ** Dequeue only `size` times, and for each dequeued node, enqueue their children.
    ** Check if the node is the last one in its level and add it to the answer.

*Implementation*:

[source, javascript]
----
include::interview-questions/binary-tree-right-side-view.js[tags=description;solution]
----

This problem is also possible to be solved using DFS. The trick is to start with the right child and add it to the solution when it is the first one on its level.

[source, javascript]
----
include::interview-questions/binary-tree-right-side-view.js[tag=dfs]
----

The complexity of any of the BFS methods or DFS is similar.

*Complexity Analysis*:

- Time: `O(n)`. We visit every node, once.
- Space: `O(n)`. For BFS, the worst-case space is given by the maximum *width*. That is when the binary tree is complete so that the last level would have `(n-1)/2` nodes, thus `O(n)`. For the DFS, the space complexity will be given by the tree's maximum *height*. In the worst-case, the binary tree is skewed to the right so that we will have an implicit call stack of size `n`.



:leveloffset: +1

=== Solutions for Hash Map Questions
(((Interview Questions Solutions, Hash Map)))

:leveloffset: -1

[#hashmap-q-two-sum]
include::content/part02/hash-map.asc[tag=hashmap-q-two-sum]
// include::content/part02/hash-map.asc[tag=hashmap-q-two-sum]

This simple problem can have many solutions; let's explore some.

_Brute force_

One brute force approach could be doing two for loops. We sum two different numbers and check if they add up to the target. If yes, we return, and if not, we keep increasing the indices until we check every possible pair.

[source, javascript]
----
include::interview-questions/two-sum.js[tags=twoSumBrute]
----

This approach's time complexity is `O(n^2)`, because we visit every number twice in the worst-case. While the space complexity is `O(1)`.

Can we trade space for time? Yes!

_Map_

Based on `nums[i] + nums[j] === target` we can say that `num[j] === target - nums[i]`. We can do one pass and check if we have seen any number equal to `target - nums[i]`. A map is perfect for this job. We could have a HashMap that maps `num` to `index`. Let's see the algorithms to make it work.


*Algorithm*:

* Visit every number once
** Calculate the complement `target - nums[i]`.
** If the complement exists, return its index and the current index.
** If not, save the complement and the index number.

*Implementation*:

[source, javascript]
----
include::interview-questions/two-sum.js[tags=description;solution]
----

*Complexity Analysis*:

- Time: `O(n)`. We visit every number once.
- Space: `O(n)`. In the worst-case scenario, we don't find the target, and we ended up with a map with all the numbers from the array.


[#hashmap-q-subarray-sum-equals-k]
include::content/part02/hash-map.asc[tag=hashmap-q-subarray-sum-equals-k]
// include::content/part02/hash-map.asc[tag=hashmap-q-subarray-sum-equals-k]

This problem has multiple ways to solve it. Let's explore some.

_Brute force_

The most straightforward one is to convert the requirements into code:
generate all possible subarrays, add them up, and check how many are equal to k.

[source, javascript]
----
include::interview-questions/subarray-sum-equals-k.js[tags=subarraySumBrute1]
----

This solution's time complexity is `O(n^3)` because of the 3 nested loops.

How can we do better? Notice that the last for loop, compute the sum repeatedly just to add one more.
Let's fix that!

_Cummulative Sum_

For this solution, instead of computing the sum from `i` to `j` all the time. We can calculate a cumulative sum. Every time we see a new number, we add it to the aggregate.

Since we want all possible subarray, We can increase `i` and get sum for each:

[source, javascript]
----
array = [1, 2, 3, 0, 1, 4, 0, 5];

// cummulative sum from left to right with i = 0
sum = [1, 3, 6, 6, 7, 11, 11, 16];
// cummulative sum from left to right with i = 1
sum = [2, 5, 5, 6, 10, 10, 15];
// cummulative sum from left to right with i = 2
sum = [3, 3, 4, 8, 8, 13];
// ... and so on ...
// cummulative sum from left to right with i = 7
sum = [5];
----

Here's the code:

[source, javascript]
----
include::interview-questions/subarray-sum-equals-k.js[tags=subarraySumBrute1]
----

The time complexity for this solution is better, `O(n^2)`. Can we still do better?

_Map_

Let's get the intution from our previous cummulative sum:

[source, javascript]
----
subarraySum([1, 2, 3, 0, 1, 4, 0, 5], 5); // k = 5

// cummulative sum from left to right is
sum = [1, 3, 6, 6, 7, 11, 11, 16];
//           ^  ^
----

Notice that when the array has a 0, the cumulative sum has a repeated number. If you subtract those numbers, it will give you zero. In the same way, If you take two other ranges and subtract them (`sum[j] - sum[i]`), it will give you the sum of that range `sum(num[i]...num[j])`.

For instance, if we take the index `2` and `0` (with values 6 and 1) and susbtract them we get `6-1=5`. To verify we can add the array values from index 0 to 2, `sum([1, 2, 3]) === 5`.

With that intuition, we can use a Map to keep track of the aggregated sum and the number of times that sum.

*Algorithm*:

* Start sum at 0
* Visit every number on the array
** Compute the cumulative sum
** Check if `sum - k` exits; if so, it means that there's a subarray that adds up to k.
** Save the sum and the number of times that it has occurred.

*Implementation*:

[source, javascript]
----
include::interview-questions/subarray-sum-equals-k.js[tags=description;solution]
----

You might wonder, what the map is initialized with `[0, 1]`. Consider this test case:

[source, javascript]
----
subarraySum([1], 1); // k = 1
----

The sum is 1, however `sum - k` is `0`. If it doesn't exist on the map, we will get the wrong answer since that number adds up to `k`. We need to add an initial case on the map: `map.set(0, 1)`. If `nums[i] - k = 0`, then that means that `nums[i] = k` and should be part of the solution.

*Complexity Analysis*:

- Time: `O(n)`. We visit every number once.
- Space: `O(n)`. The map size will be the same as the original array.



:leveloffset: +1

=== Solutions for Set Questions
(((Interview Questions Solutions, Set)))

:leveloffset: -1


[#set-q-most-common-word]
include::content/part02/hash-set.asc[tag=set-q-most-common-word]

This problem requires multiple steps. We can use a `Set` for quickly looking up banned words. For getting the count of each word, we used a `Map`.

*Algorithm*:

- Convert text to lowercase.
- Remove any special characters `!?',;.`.
- Convert the paragraph into words array.
- Count how many times words occur.
- Exclude banned words from counts.
- Return the word (or first one) that is the most repeated.

*Implementation*:

[source, javascript]
----
include::interview-questions/most-common-word.js[tags=description;solution]
----

Here are heavily relying on Regular Expressions:

- `\W+` would match all non-words.
- `\s+` catches all whitespace.

The line that is mapping words to count seems very busy. Here's another version of the same code a little bit more explicit:

[source, javascript]
----
include::interview-questions/most-common-word.js[tags=explicit]
----

*Complexity Analysis*:

- Time: `O(m + n)`, where `n` is paragraph length and `m` is the number of banned words. If we were NOT using a `Set` for prohibited words, then the runtime would have been `O(mn)`.
- Space: `O(m + n)`. The extra space complexity is given by the size of the `Map` and `Set`.





[#set-q-longest-substring-without-repeating-characters]
include::content/part02/hash-set.asc[tag=set-q-longest-substring-without-repeating-characters]

One of the most efficient ways to find repeating characters is using a `Map` or `Set`. Use a `Map` when you need to keep track of the count/index (e.g., string -> count) and use a `Set` when you only need to know if there are repeated characters or not.

*Algorithm*:

* Visit each letter.
** Insert the letter on a Set.
** Keep track of the maximum size of the Set in `max`.
** If the letter has been seen before, delete until there's no duplicate.
* Return max.

*Implementation*:

[source, javascript]
----
include::interview-questions/longest-substring-without-repeating-characters.js[tags=description;solution]
----

We could also have used a Map and keep track of the indexes, but that's not necessary. In this case, the `Set` is all we need.

*Complexity Analysis*:

- Time: `O(n)`. We visit each letter once.
- Space: `O(W)`, where `W` is the max length of non-repeating characters. The maximum size of the Set gives the space complexity. In the worst-case scenario, all letters are unique (`W = n`), so our space complexity would be `O(n)`. In the avg. case where there are one or more duplicates, it uses less space than `n`, because `W < n`.







:leveloffset: +1

=== Solutions for Graph Questions
(((Interview Questions Solutions, Graph)))

:leveloffset: -1


[#graph-q-course-schedule]
include::content/part03/graph-search.asc[tag=graph-q-course-schedule]

Basically, we have to detect if the graph has a cycle or not.
There are multiple ways to detect cycles on a graph using BFS and DFS.

One of the most straightforward ways to do it is using DFS one each course (node) and traverse their prerequisites (neighbors). If we start in a node, and then we see that node again, we found a cycle! (maybe)

A critical part of solving this exercise is coming up with good test cases. Let's examine these two:

[graphviz, course-schedule-examples, png]
....
digraph G {
  subgraph cluster_1 {
    a0 -> a1 -> a2
    a0 -> a2 [color=gray]
    label = "Example A"
  }

  subgraph cluster_2 {
    b0 -> b1 -> b2 -> b3
    b3 -> b1 [color=red]
    label = "Example B";
  }
}
....

Let's say we are using a regular DFS, where we visit the nodes and keep track of visited nodes. If we test the example A, we can get to the course 2 (a2) in two ways. So, we can't blindly assume that "seen" nodes are because of a cycle. To solve this issue, we can keep track of the parent.

For example B, if we start in course 0 (b0), we can find a cycle. However, the cycle does not involve course 0 (parent). When we visit course 1 (b1) and mark it as the parent, we will see that reach to course 1 (b1) again. Then, we found a cycle!

[source, javascript]
----
include::interview-questions/course-schedule.js[tags=brute1]
----

We built the graph on the fly as an adjacency list (Map + Arrays).
Then we visited each node, checking if there it has cycles. If none has cyles, then we return true.

The cycle check uses DFS. We keep track of seen nodes and also who the parent is. If we get to the parent more than once, we have a cycle like examples A and B.

What's the time complexity?

We visite every node/vertex: `O(|V|)` and then for every node, we visite all it's edges, so we have `O(|V|*|E|)`.

Can we do better?

There's no need to visit nodes more than once. Instead of having a local `seen` variable for each node, we can move it outside the loop. However, it won't be a boolean anymore (seen or not seen). We could see nodes more than once, without being in a cycle (example A). One idea is to have 3 states: `unvisited` (0), `visiting` (1) and `visited` (2). Let's devise the algorithm:

*Algorithm*:

* Build a graph as an adjacency list (map + arrays).
* Fill in every prerequisite as an edge on the graph.
* Visit every node and if there's a cycle, return false.
** When we start visiting a node, we mark it as 1 (visiting)
** Visit all its adjacent nodes
** Mark current node as 2 (visited) when we finish visiting neighbors.
** If we see a node in visiting state more than once, it's a cycle!
** If we see a node in a visited state, skip it.

*Implementation*:

[source, javascript]
----
include::interview-questions/course-schedule.js[tags=description;solution]
----

In the first line, we initialize the map with the course index and an empty array.
This time the `seen` array is outside the recursion.

*Complexity Analysis*:

- Time: `O(|V| + |E|)`. We go through each node and edge only once.
- Space: `O(|V| + |E|)`. The size of the adjacency list.




//
[#graph-q-critical-connections-in-a-network]
include::content/part03/graph-search.asc[tag=graph-q-critical-connections-in-a-network]

On idea to find if a path is critical is to remove it. If we visit the graph and see that some nodes are not reachable, then, oops, It was critical!

We can code precisely that. We can remove one link at a time and check if all other nodes are reachable. It's not very efficient, but it's a start.

[source, javascript]
----
include::interview-questions/critical-connections-in-a-network.js[tags=criticalConnectionsBrute1]
----

We are using a function `areAllNodesReachable`, which implements a BFS for visiting the graph, but DFS would have worked too. The runtime is `O(|E| + |V|)`, where `E` is the number of edges and `V` the number of nodes/servers. In `criticalConnectionsBrute1`, We are looping through all `connections` (`E`) to remove one connection at a time and then checking if all servers are still reachable with `areAllNodesReachable`.

The time complexity is `O(|E|^2 * |V|)`. Can we do it on one pass? Sure we can!

*Tarjan's Strongly Connected Components Algorithms*

A connection is critical only if it's not part of the cycle.

In other words, a critical path is like a bridge that connects islands; if you remove it you won't cross from one island to the other.

Connections that are part of the cycle (blue) have redundancy. If you eliminate one, you can still reach other nodes. Check out the examples below.

[graphviz, critical-connections-sol-examples, png]
....
graph G {
  subgraph cluster_0 {
    a0 -- a1 [color=blue]
    a1 -- a2 [color=blue]
    a2 -- a0 [color=blue]
    a1 -- a3 [color=blue]
    a3 -- a2 [color=blue]
    label = "Example A";
  }

  subgraph cluster_3 {
    b0 -- b1 [color=blue]
    b1 -- b2 [color=blue]
    b2 -- b0 [color=blue]
    b1 -- b3 [color=red]
    b3 -- b2 [color=transparent] // removed
    label = "Example B";
  }

  subgraph cluster_1 {
    c0 -- c1 -- c2 -- c3 [color=red]
    label = "Example C";
  }
}
....

The red connections are critical; if we remove any, some servers won't be reachable.

We can solve this problem in one pass using DFS. But for that, we keep track of the nodes that are part of a loop (strongly connected components). We use the time of visit (or depth in the recursion) each node.

For example C, if we start on `c0`, it belongs to group 0, then we move c1, c2, and c3, increasing the depth counter. Each one will be on its own group since there's no loop.

For example B, we can start at `b0`, and then we move to `b1` and `b2`. However, `b2` circles back to `b0`, which is on group 0. We can update the group of `b1` and `b2` to be 0 since they are all connected in a loop.

For an *undirected graph*, If we found a node on our DFS, that we have previously visited, we found a loop! We can mark all of them with the lowest group number. We know we have a critical path when it's a connection that links two different groups. For example A, they all will belong to group 0, since they are all in a loop. For Example B, we will have `b0`, `b1`, and `b2` on the same group while `b3` will be on a different group.

*Algorithm*:

* Build the graph as an adjacency list (map + array)
* Run dfs on any node. E.g. `0`.
** Keep track of the nodes that you have seen using `group` array. But instead of marking them as seen or not. Let's mark it with the `depth`.
** Visit all the adjacent nodes that are NOT the parent.
** If we see a node that we have visited yet, do a DFS on it and increase the depth.
** If the adjacent node has a lower grouping number, update the current node with it.
** If the adjacent node has a higher grouping number, then we found a critical path.

*Implementation*:

[source, javascript]
----
include::interview-questions/critical-connections-in-a-network.js[tags=description;solution]
----

This algorithm only works with DFS.

*Complexity Analysis*:

- Time: `O(|E| + |V|)`. We visit each node and edge only once.
- Space: `O(|E| + |V|)`. The graph has all the edges and nodes. Additionally, we use the `group` variable with a size of `|V|`.







//

:leveloffset: +1

=== Solutions for Sorting Questions
(((Interview Questions Solutions, sorting)))

:leveloffset: -1


[#sorting-q-merge-intervals]
include::content/part04/sorting-algorithms.asc[tag=sorting-q-merge-intervals]

The first thing we need to understand is all the different possibilities for overlaps:

// image::merge-intervals-cases.png[merge intervals cases] // blurry
// image::intervals-overlap-cases.jpg[merge intervals cases] // too big
// image::intervals-overlap-cases.svg[merge intervals cases] // errors

// my own image
image::intervals-overlap-cases-owned.png[merge intervals cases]

One way to solve this problem is sorting by start time. That will eliminate half of the cases! A will always start before B. Only 3 cases apply:
- No overlap: E.g.,`[[1, 3], [4, 6]]`.
- Overlap at the end: E.g., `[[1, 3], [2, 4]]`.
- Eclipse: E.g.,`[[1, 9], [3, 7]]`.

*Algorithm*:

* Sort intervals by start time
* If the `curr`ent interval's start time is _equal_ or less than the `last` interval's end time, then we have an overlap.
** Overlaps has two cases: 1) `curr`'s end is larger 2) `last`'s end is larger. For both cases, `Math.max` works.
* If there's no overlap, we add the interval to the solution.

*Implementation*:

[source, javascript]
----
include::interview-questions/merge-intervals.js[tags=description;solution]
----

For the first interval, it will be added straight to the solution array. For all others, we will make a comparison.

*Complexity Analysis*:

- Time: `O(n log n)`. Standard libraries have a sorting time of `O(n log n)`, then we visit each interval in `O(n)`.
- Space: `O(n)`. In the worst-case is when there are no overlapping intervals. The size of the solution array would be `n`.







//

[#sorting-q-sort-colors]
include::content/part04/sorting-algorithms.asc[tag=sorting-q-sort-colors]

We are asked to sort an array with 3 possible values. If we use the standard sorting method `Array.sort`, that will be `O(n log n)`. However, there's a requirement to solve it in linear time and constant space complexity.

The concept of quicksort can help here. We can choose `1` as a pivot and move everything less than 1 to the left and everything more significant than 1 to the right.

*Algorithm*:

* Initialize 3 pointers: `left = 0`, `right = len - 1` and `current = 0`.
* While the `current` pointer is less than `right`
** If `current` element is less than pivot 1, swap it to the left and increase the `left` and `current` pointer.
*** We can safely increase the current pointer
** If `current` element is bigger than pivot 1, swap it to the right and decrease `right` pointer.
*** Here, we don't increase the `current` pointer because the number that we swapped with could be another 2 and we might need to keep swapping while decreasing `right`.

*Implementation*:

[source, javascript]
----
include::interview-questions/sort-colors.js[tags=description;solution]
----

We are using the destructive assignment to swap the elements. Here's another version a little bit more compact.

[source, javascript]
----
include::interview-questions/sort-colors.js[tags=compact]
----

*Complexity Analysis*:

- Time: `O(n)`. We only visit each number once.
- Space: `O(1)`. Operations are in-place. Only O(1) space variables were used.







//
